### Links úteis

* 37 Reasons why your Neural Network is not working. [post](https://blog.slavv.com/37-reasons-why-your-neural-network-is-not-working-4020854bd607)
* AR-MDN: AR-MDN: Associative and Recurrent Mixture Density Networks for eRetail Demand Forecasting. [paper](https://arxiv.org/pdf/1803.03800.pdf)
* Are categorical variables getting lost in your random forests? [post](https://roamanalytics.com/2016/10/28/are-categorical-variables-getting-lost-in-your-random-forests/)
* Artificial Neural Networks Applied to Taxi Destination Prediction. [paper](https://arxiv.org/pdf/1508.00021.pdf)
* Avoiding headaches with tf.metrics. [post](http://ronny.rest/blog/post_2017_09_11_tf_metrics/)
* Beyond Word Embeddings Part 2. [post](https://towardsdatascience.com/beyond-word-embeddings-part-2-word-vectors-nlp-modeling-from-bow-to-bert-4ebd4711d0ec)
* Comprehensive Hands-on Guide to Transfer Learning with Real-World Applications in Deep Learning, A. [post](https://towardsdatascience.com/a-comprehensive-hands-on-guide-to-transfer-learning-with-real-world-applications-in-deep-learning-212bf3b2f27a)
* CS230 (Deep Learning) [notes](https://cs230-stanford.github.io/)
* Cross-validation based Nonlinear Shrinkage. [paper](https://arxiv.org/pdf/1611.00798.pdf)
* DCGAN Faces Tutorial. [post](https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html)
* DeepAR: Probabilistic Forecasting with Autoregressive Recurrent Networks. [paper](https://arxiv.org/pdf/1704.04110.pdf)
* Deep Learning. [book](https://www.deeplearningbook.org/)
* Deep contextualized word representations. [paper](http://www.aclweb.org/anthology/N18-1202) [repo](https://github.com/allenai/allennlp/blob/master/tutorials/how_to/elmo.md)
* Do Not Log-Transform Count Data, Bitches! [post](https://www.r-bloggers.com/do-not-log-transform-count-data-bitches/)
* Dopamine: a research framework for fast prototyping of reinforcement learning algorithms. [repo](https://github.com/google/dopamine)
* Efficient Learning using Forward-Backward Splitting. [paper](http://papers.nips.cc/paper/3793-efficient-learning-using-forward-backward-splitting.pdf)
* Engineering Extreme Event Forecasting at Uber with Recurrent Neural Networks. [post](https://eng.uber.com/neural-networks/)
* Fixup normalization: residual learning without normalization. [paper](https://openreview.net/pdf?id=H1gsz30cKX)
* Forecasting Across Time Series Databases using Recurrent Neural Networks on Groups of Similar Series: A Clustering Approach. [paper](https://arxiv.org/pdf/1710.03222.pdf)
* Guide for using the Wavelet Transform in Machine Learning, A. [post](https://www.datasciencecentral.com/profiles/blogs/a-guid-for-using-the-wavelet-transform-in-machine-learning)
* Improved Variational Inference with Inverse Autoregressive Flow. [paper](https://arxiv.org/pdf/1606.04934.pdf)
* Layer Normalization. [paper](https://arxiv.org/abs/1607.06450)
* Machine Learning for Combinatorial Optimization: a Methodological Tour d’Horizon. [paper](https://arxiv.org/pdf/1811.06128.pdf)
* Mixture Density Network. [paper](https://publications.aston.ac.uk/373/1/NCRG_94_004.pdf)
* Mixture Density Networks implementation for distribution and uncertainty estimation. [repo](https://github.com/axelbrando/Mixture-Density-Networks-for-distribution-and-uncertainty-estimation)
* Neural Processes. [paper](https://arxiv.org/pdf/1807.01622.pdf) [repo](https://github.com/deepmind/conditional-neural-process)
* Non-parametric Estimation of Integral Probability Metrics. [paper](https://web.archive.org/web/20130305001428/http://cosmal.ucsd.edu/~gert/papers/isit_2010.pdf)
* Nevergrad: An open source tool for derivative-free optimization. [post](https://code.fb.com/ai-research/nevergrad/)
* Normalizing Flows. [post](https://akosiorek.github.io/ml/2018/04/03/norm_flows.html)
* Open sourcing TRFL: a library of reinforcement learning building blocks. [post](https://deepmind.com/blog/trfl/)
* Optimal forecast reconciliation for hierarchical and grouped time series through trace minimization. [paper](https://robjhyndman.com/papers/mint.pdf)
* Optimal reconciliation approach, The. [post](https://otexts.com/fpp2/reconciliation.html)
* Papers with Code. [repo](https://github.com/zziz/pwc)
* PyTorch Recipes: A Problem-Solution Approach. [book](http://file.allitebooks.com/20190128/PyTorch%20Recipes.pdf)
* Review and comparison of strategies for multi-step ahead time series forecasting based on the NN5 forecasting competition, A. [paper](https://arxiv.org/pdf/1108.3259.pdf) 
* Sample Efficient Adaptive Text-to-Speech. [paper](https://arxiv.org/pdf/1809.10460.pdf) [demo](https://sample-efficient-adaptive-tts.github.io/demo/)
* Snorkel DryBell: A Case Study in Deploying Weak Supervision at Industrial Scale. [link](https://arxiv.org/pdf/1812.00417.pdf)
* Spinning Up in Deep RL. [link](https://spinningup.openai.com/en/latest)
* SOTAWHAT: Returns latest research results by crawling arxiv papers and summarizing abstracts. [link](https://github.com/chiphuyen/sotawhat)
* Style-Based Generator Architecture for Generative Adversarial Networks, A. [link](https://arxiv.org/pdf/1812.04948.pdf)
* Tensorflow and deep learning without a PhD series. [repo](https://github.com/GoogleCloudPlatform/tensorflow-without-a-phd)
* TensorFlow Reduces Time Taken For Metaheuristics To 0.1% Of The Original Time. [post](https://medium.com/@LeonFedden/tensorflow-reduces-time-taken-for-metaheuristics-to-0-1-of-the-original-time-30b8a8f4fc7f)
* Variational Inference with Normalizing Flows. [paper](https://arxiv.org/pdf/1505.05770.pdf)
* World Models. [demo](https://worldmodels.github.io/)


### Snippets

* ways to do gradients clipping and learning rate decay in tensorflow. [gist](https://gist.github.com/InnerPeace-Wu/6a26e00297e89134e3e8532053509d89)